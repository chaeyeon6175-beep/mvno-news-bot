import os, requests, re, time
from datetime import datetime, timedelta
from difflib import SequenceMatcher

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
NAVER_ID = os.environ.get('NAVER_CLIENT_ID')
NAVER_SECRET = os.environ.get('NAVER_CLIENT_SECRET')
NOTION_TOKEN = os.environ.get('NOTION_TOKEN')
DB_IDS = {
    "MNO": os.environ.get('DB_ID_MNO'),
    "SUBSID": os.environ.get('DB_ID_SUBSID'),
    "FIN": os.environ.get('DB_ID_FIN'),
    "SMALL": os.environ.get('DB_ID_SMALL')
}

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# ì£¼ìš” ì–¸ë¡ ì‚¬ ê°€ì¤‘ì¹˜
MAJOR_PRESS = ["ì—°í•©ë‰´ìŠ¤", "ë‰´ì‹œìŠ¤", "ë‰´ìŠ¤1", "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ", "ì „ìì‹ ë¬¸", "ë””ì§€í„¸ë°ì¼ë¦¬", "ë¨¸ë‹ˆíˆ¬ë°ì´", "ì•„ì´ë‰´ìŠ¤24"]

def get_similarity(a, b):
    """ì œëª© ìœ ì‚¬ë„ ê³„ì‚° (íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµ)"""
    a = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', a)
    b = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', b)
    return SequenceMatcher(None, a, b).ratio()

def is_telecom_industry_news(title):
    """í†µì‹  ì‚°ì—… ë³¸ì§ˆê³¼ ê´€ë ¨ëœ ê¸°ì‚¬ë§Œ í†µê³¼ (ìŠ¤í¬ì¸ , ì‡¼í•‘, ì£¼ê°€ ë“± ì œì™¸)"""
    t = title.lower().replace(' ', '')
    # ì œì™¸ ì‚°ì—…êµ°
    exclude = ["ì•¼êµ¬", "ë°°êµ¬", "ë†êµ¬", "ì¶•êµ¬", "ìŠ¤í¬ì¸ ", "ì‡¼í•‘", "ì´ì»¤ë¨¸ìŠ¤", "11ë²ˆê°€", "ì£¼ê°€", "ì¦ì‹œ", "ìƒì¥", "ìŒì•…íšŒ", "ì „ì‹œíšŒ", "ì¸ì‚¬", "ë™ì •"]
    if any(ex in t for ex in exclude): return False
    # í•„ìˆ˜ í†µì‹  í‚¤ì›Œë“œ
    include = ["ìš”ê¸ˆì œ", "ì•Œëœ°í°", "mvno", "5g", "6g", "lte", "í†µì‹ ", "ê°€ì…ì", "ë‹¨ë§ê¸°", "ë„¤íŠ¸ì›Œí¬", "ìœ ì‹¬", "esim", "ë¡œë°", "êµ¬ë…", "ê²°í•©", "ê³µì‹œì§€ì›"]
    return any(inc in t for inc in include)

def select_representative(articles):
    """ëŒ€í‘œ ê¸°ì‚¬ ì„ ì •: ì£¼ìš” ì–¸ë¡ ì‚¬(+10) > ì œëª© ê¸¸ì´(+0.1) > ìµœì‹ ìˆœ"""
    best_score = -1
    best_art = articles[0]
    for art in articles:
        score = 0
        if any(p in art['press'] for p in MAJOR_PRESS): score += 10
        score += len(art['title']) * 0.1
        if score >= best_score:
            best_score = score
            best_art = art
    return best_art

def get_refined_tags(title, db_key, default_tag):
    """DBë³„ ë°°íƒ€ì  ë¶„ë¥˜ ë° í†µì‹  3ì‚¬ ìš°ì„ ìˆœìœ„ ì ìš©"""
    if not is_telecom_industry_news(title): return None
    t = title.lower().replace(' ', '')
    
    # ì œì™¸ í‚¤ì›Œë“œ
    if any(ex in t for ex in ["skì‰´ë”ìŠ¤", "ì§€ë‹ˆë®¤ì§", "ktì•ŒíŒŒ"]): return None

    # MNO DB
    if db_key == "MNO":
        # ìíšŒì‚¬/ê¸ˆìœµ í‚¤ì›Œë“œ í¬í•¨ ì‹œ MNO ì œì™¸
        if any(x in t for x in ["í…”ë§í¬", "ì— ëª¨ë°”ì¼", "í—¬ë¡œë¹„ì „", "ìŠ¤ì¹´ì´ë¼ì´í”„", "ë¯¸ë””ì–´ë¡œê·¸", "ë¦¬ë¸Œm", "í† ìŠ¤ëª¨ë°”ì¼"]): return None
        is_3ì‚¬ = any(x in t for x in ["í†µì‹ 3ì‚¬", "ì´í†µ3ì‚¬", "í†µì‹ ì‚¬"]) or \
                 (sum([any(x in t for x in ["skt", "skí…”ë ˆì½¤"]), any(x in t for x in ["kt", "ì¼€ì´í‹°"]), any(x in t for x in ["lgu+", "lgìœ í”ŒëŸ¬ìŠ¤"])]) >= 2)
        if is_3ì‚¬: return [{"name": "í†µì‹  3ì‚¬"}]
        if any(x in t for x in ["skt", "skí…”ë ˆì½¤"]): return [{"name": "SKT"}]
        if any(x in t for x in ["kt", "ì¼€ì´í‹°"]): return [{"name": "KT"}]
        if any(x in t for x in ["lgìœ í”ŒëŸ¬ìŠ¤", "lgu+"]): return [{"name": "LG U+"}]
        return None

    # ìíšŒì‚¬/ê¸ˆìœµ/ì¤‘ì†Œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    # ... (ìƒëµëœ íƒœê·¸ ë§¤í•‘ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ì ìš©ë¨)
    return [{"name": default_tag}]

def post_notion(db_id, title, link, tags, pub_date):
    target_id = re.sub(r'[^a-fA-F0-9]', '', db_id)
    data = {
        "parent": {"database_id": target_id},
        "properties": {
            "ì œëª©": {"title": [{"text": {"content": title}}]},
            "ë‚ ì§œ": {"rich_text": [{"text": {"content": pub_date}}]},
            "ë§í¬": {"url": link},
            "ë¶„ë¥˜": {"multi_select": tags}
        }
    }
    res = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=data)
    return res.status_code == 200

def collect(db_key, configs, days):
    db_id = DB_IDS.get(db_key)
    if not db_id: return
    allowed_dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days + 1)]

    for keywords, limit, default_tag in configs:
        print(f"ğŸ” {db_key} - {default_tag} ìˆ˜ì§‘ ì¤‘...")
        query = " ".join(keywords)
        raw_items = []
        for sort in ["date", "sim"]:
            res = requests.get(f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100&sort={sort}",
                               headers={"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET})
            if res.status_code == 200: raw_items.extend(res.json().get('items', []))

        # 1. 1ì°¨ í•„í„°ë§ (ì‚°ì—… í•„í„° ë° íƒœê·¸ ë¶€ì—¬)
        valid_articles = []
        for item in raw_items:
            title = item['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
            tags = get_refined_tags(title, db_key, default_tag)
            if tags:
                valid_articles.append({
                    'title': title, 'link': item['link'], 'tags': tags,
                    'date': datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900').strftime('%Y-%m-%d'),
                    'press': item.get('originallink', '') # ë„¤ì´ë²„ëŠ” ì–¸ë¡ ì‚¬ëª…ì„ ë”°ë¡œ ì•ˆì¤˜ì„œ ë§í¬ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì¶”ê°€ í¬ë¡¤ë§ í•„ìš”
                })

        # 2. ìœ ì‚¬ ì£¼ì œ ê·¸ë£¹í™” (Clustering) - ë™ì¼ ì£¼ì œ ê¸°ì‚¬ ì œê±°
        unique_groups = []
        for art in valid_articles:
            found = False
            for group in unique_groups:
                if get_similarity(art['title'], group[0]['title']) > 0.5: # 50% ì´ìƒ ìœ ì‚¬í•˜ë©´ ë™ì¼ ì£¼ì œë¡œ íŒë‹¨
                    group.append(art); found = True; break
            if not found: unique_groups.append([art])

        # 3. ëŒ€í‘œ ê¸°ì‚¬ ì„ ì • ë° íƒœê·¸ë³„ ìµœëŒ€ 12ê°œ ì¶œë ¥
        count = 0
        for group in unique_groups:
            rep = select_representative(group)
            is_min = (db_key != "MNO") and (count < 2)
            if rep['date'] in allowed_dates or is_min:
                if post_notion(db_id, rep['title'], rep['link'], rep['tags'], rep['date']):
                    count += 1
            if count >= 12: break # [í•„ìˆ˜] íƒœê·¸ë‹¹ ìµœëŒ€ 12ê°œ ì œí•œ

if __name__ == "__main__":
    for k in DB_IDS: 
        # DB ë¹„ìš°ê¸° ë¡œì§ì€ ì‚¬ìš©ì í™˜ê²½ì— ë§ì¶° ì‹¤í–‰
        # clear_notion_database(DB_IDS[k])
        pass

    # MNO ìˆ˜ì§‘
    collect("MNO", [(["í†µì‹ 3ì‚¬"], 12, "í†µì‹  3ì‚¬"), (["SKT"], 12, "SKT"), (["KT"], 12, "KT"), (["LGìœ í”ŒëŸ¬ìŠ¤"], 12, "LG U+")], 7)
    # ìíšŒì‚¬ ìˆ˜ì§‘
    collect("SUBSID", [(["SKí…”ë§í¬"], 12, "SKí…”ë§í¬"), (["KTì— ëª¨ë°”ì¼"], 12, "KT Mëª¨ë°”ì¼"), (["LGí—¬ë¡œë¹„ì „"], 12, "LGí—¬ë¡œë¹„ì „"), (["ìŠ¤ì¹´ì´ë¼ì´í”„"], 12, "KTìŠ¤ì¹´ì´ë¼ì´í”„"), (["ë¯¸ë””ì–´ë¡œê·¸"], 12, "ë¯¸ë””ì–´ë¡œê·¸")], 60)
    # ê¸ˆìœµê¶Œ ìˆ˜ì§‘
    collect("FIN", [(["í† ìŠ¤ëª¨ë°”ì¼", "ë¦¬ë¸Œëª¨ë°”ì¼", "ìš°ë¦¬ì›ëª¨ë°”ì¼"], 12, "ê¸ˆìœµê¶Œ")], 60)
    # ì¤‘ì†Œ ì•Œëœ°í°
    collect("SMALL", [(["ì•Œëœ°í° ë‰´ìŠ¤"], 12, "ì¤‘ì†Œ ì•Œëœ°í°")], 60)
