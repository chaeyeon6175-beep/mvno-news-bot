import os, requests, re, time
from datetime import datetime, timedelta
from difflib import SequenceMatcher

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì‚¬ì „ì— ì„¤ì • í•„ìš”)
NAVER_ID = os.environ.get('NAVER_CLIENT_ID')
NAVER_SECRET = os.environ.get('NAVER_CLIENT_SECRET')
NOTION_TOKEN = os.environ.get('NOTION_TOKEN')
DB_IDS = {
    "MNO": os.environ.get('DB_ID_MNO'),
    "SUBSID": os.environ.get('DB_ID_SUBSID'),
    "FIN": os.environ.get('DB_ID_FIN'),
    "SMALL": os.environ.get('DB_ID_SMALL')
}

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

def get_similarity(a, b):
    a = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', a)
    b = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', b)
    return SequenceMatcher(None, a, b).ratio()

def is_telecom_industry_news(title):
    t = title.lower().replace(' ', '')
    # ìŠ¤í¬ì¸ , ì‡¼í•‘, ì£¼ê°€ ë“± í†µì‹  ì„œë¹„ìŠ¤ì™€ ë¬´ê´€í•œ ì‚°ì—…êµ° ë°°ì œ
    exclude = ["ì•¼êµ¬", "ë°°êµ¬", "ë†êµ¬", "ì¶•êµ¬", "ìŠ¤í¬ì¸ ", "ì‡¼í•‘", "ì´ì»¤ë¨¸ìŠ¤", "11ë²ˆê°€", "ì£¼ê°€", "ì¦ì‹œ", "ìƒì¥", "ìŒì•…íšŒ", "ì „ì‹œíšŒ", "ì¸ì‚¬", "ë™ì •"]
    if any(ex in t for ex in exclude): return False
    # í†µì‹  ì‚°ì—… í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    include = ["ìš”ê¸ˆì œ", "ì•Œëœ°í°", "mvno", "5g", "6g", "lte", "í†µì‹ ", "ê°€ì…ì", "ë‹¨ë§ê¸°", "ë„¤íŠ¸ì›Œí¬", "ìœ ì‹¬", "esim", "ë¡œë°", "ê²°í•©", "ê³µì‹œì§€ì›"]
    return any(inc in t for inc in include)

def get_final_tags(title, db_key, default_tag):
    if not is_telecom_industry_news(title): return None
    t = title.lower().replace(' ', '')
    if any(ex in t for ex in ["skì‰´ë”ìŠ¤", "ì§€ë‹ˆë®¤ì§", "ktì•ŒíŒŒ"]): return None

    # 1. MNO DB (í†µì‹ 3ì‚¬)
    if db_key == "MNO":
        if any(x in t for x in ["í…”ë§í¬", "ì— ëª¨ë°”ì¼", "í—¬ë¡œë¹„ì „", "ìŠ¤ì¹´ì´ë¼ì´í”„", "ë¯¸ë””ì–´ë¡œê·¸", "ë¦¬ë¸Œm", "í† ìŠ¤ëª¨ë°”ì¼"]): return None
        sa3_keywords = ["í†µì‹ 3ì‚¬", "ì´í†µ3ì‚¬", "í†µì‹ ì—…ê³„", "í†µì‹ ì£¼", "ì´í†µì‚¬ê³µí†µ", "3ì‚¬"]
        skt, kt, lg = any(x in t for x in ["skt", "skí…”ë ˆì½¤"]), any(x in t for x in ["kt", "ì¼€ì´í‹°"]), any(x in t for x in ["lgu+", "lgìœ í”ŒëŸ¬ìŠ¤"])
        if any(x in t for x in sa3_keywords) or (skt + kt + lg >= 2): return [{"name": "í†µì‹  3ì‚¬"}]
        elif skt: return [{"name": "SKT"}]
        elif kt: return [{"name": "KT"}]
        elif lg: return [{"name": "LG U+"}]
        return [{"name": default_tag}]

    # 2. ìíšŒì‚¬ DB (5ê°œì‚¬)
    elif db_key == "SUBSID":
        subsid_map = {
            "SKí…”ë§í¬": ["skí…”ë§í¬", "7ëª¨ë°”ì¼", "ì„¸ë¸ëª¨ë°”ì¼"],
            "KT Mëª¨ë°”ì¼": ["ktmëª¨ë°”ì¼", "ktì— ëª¨ë°”ì¼"],
            "LGí—¬ë¡œë¹„ì „": ["lgí—¬ë¡œë¹„ì „", "í—¬ë¡œëª¨ë°”ì¼"],
            "KTìŠ¤ì¹´ì´ë¼ì´í”„": ["ìŠ¤ì¹´ì´ë¼ì´í”„", "skylife"],
            "ë¯¸ë””ì–´ë¡œê·¸": ["ë¯¸ë””ì–´ë¡œê·¸", "ìœ ëª¨ë°”ì¼", "uëª¨ë°”ì¼"]
        }
        for name, kws in subsid_map.items():
            if any(k in t for k in kws): return [{"name": name}]
        return None

    # 3. ê¸ˆìœµ DB (3ì‚¬)
    elif db_key == "FIN":
        fin_map = {"í† ìŠ¤ëª¨ë°”ì¼": ["í† ìŠ¤ëª¨ë°”ì¼"], "ìš°ë¦¬ì›ëª¨ë°”ì¼": ["ìš°ë¦¬ì›ëª¨ë°”ì¼"], "KBë¦¬ë¸Œëª¨ë°”ì¼": ["ë¦¬ë¸Œëª¨ë°”ì¼", "ë¦¬ë¸Œm"]}
        for name, kws in fin_map.items():
            if any(k in t for k in kws): return [{"name": name}]
        return None

    # 4. ì¤‘ì†Œ ì‚¬ì—…ì DB (ì§€ì • ì—…ì²´ëª…ì´ ì œëª©ì— ìˆì„ ë•Œë§Œ ì¶œë ¥)
    elif db_key == "SMALL":
        small_map = {
            "ì•„ì´ì¦ˆëª¨ë°”ì¼": ["ì•„ì´ì¦ˆëª¨ë°”ì¼", "ì•„ì´ì¦ˆë¹„ì „"],
            "í”„ë¦¬ëª¨ë°”ì¼": ["í”„ë¦¬í…”ë ˆì½¤", "í”„ë¦¬ëª¨ë°”ì¼"],
            "ì—ë„¥ìŠ¤í…”ë ˆì½¤": ["ì—ë„¥ìŠ¤í…”ë ˆì½¤", "aëª¨ë°”ì¼"],
            "ìœ ë‹ˆì»´ì¦ˆ": ["ìœ ë‹ˆì»´ì¦ˆ", "ëª¨ë¹„ìŠ¤íŠ¸"],
            "ì¸ìŠ¤ì½”ë¹„": ["ì¸ìŠ¤ì½”ë¹„", "í”„ë¦¬í‹°"],
            "ì„¸ì¢…í…”ë ˆì½¤": ["ì„¸ì¢…í…”ë ˆì½¤", "ìŠ¤ë…¸ìš°ë§¨"],
            "í°ì‚¬ëŒ": ["í°ì‚¬ëŒ", "ì´ì•¼ê¸°ëª¨ë°”ì¼"]
        }
        # ì œëª©ì— ì—…ì²´ëª…ì´ ìˆëŠ”ì§€ ê²€ì‚¬
        for name, kws in small_map.items():
            if any(k in t for k in kws): return [{"name": name}]
        return None  # ì—…ì²´ëª…ì´ ì—†ìœ¼ë©´ ì•„ì˜ˆ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ
    
    return None

def post_notion(db_id, title, link, tags, pub_date):
    """ì œëª©ì— í•˜ì´í¼ë§í¬ë¥¼ ê±¸ì–´ ë…¸ì…˜ì— ì €ì¥"""
    target_id = re.sub(r'[^a-fA-F0-9]', '', db_id)
    data = {
        "parent": {"database_id": target_id},
        "properties": {
            "ì œëª©": {"title": [{"text": {"content": title, "link": {"url": link}}}]},
            "ë‚ ì§œ": {"rich_text": [{"text": {"content": pub_date}}]},
            "ë§í¬": {"url": link},
            "ë¶„ë¥˜": {"multi_select": tags}
        }
    }
    res = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=data)
    return res.status_code == 200

def collect(db_key, configs, days):
    db_id = DB_IDS.get(db_key)
    if not db_id: return
    allowed_dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days + 1)]
    
    seen_urls = set()
    seen_titles = [] 

    for keywords, limit, default_tag in configs:
        tag_count = 0 
        print(f"ğŸ” {db_key} - {default_tag} ì‘ì—… ì¤‘...")
        
        query = " ".join(keywords)
        # ê²€ìƒ‰ì€ ìµœì‹ ìˆœìœ¼ë¡œ í•œ ë²ˆë§Œ
        url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100&sort=date"
        res = requests.get(url, headers={"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET})
        
        if res.status_code != 200: continue
        raw_items = res.json().get('items', [])

        for item in raw_items:
            if tag_count >= 12: break # íƒœê·¸ë‹¹ ìµœëŒ€ 12ê°œ ì œí•œ
            if item['link'] in seen_urls: continue

            title = item['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
            
            # 1. ì£¼ì œ ì¤‘ë³µ ì œê±° (ìœ ì‚¬ë„ 45% ì´ˆê³¼ ì‹œ íŒ¨ìŠ¤)
            is_duplicate_topic = False
            for seen_title in seen_titles:
                if get_similarity(title, seen_title) > 0.45:
                    is_duplicate_topic = True
                    break
            if is_duplicate_topic: continue

            # 2. íƒœê·¸ ë° ì—…ì²´ëª… ë§¤ì¹­ (ì—…ì²´ëª… ì—†ìœ¼ë©´ None ë°˜í™˜ë¨)
            tags = get_final_tags(title, db_key, default_tag)
            
            if tags:
                # MNOëŠ” íƒœê·¸ ì¼ê´€ì„± ìœ ì§€
                if db_key == "MNO" and tags[0]['name'] != default_tag: continue
                
                p_date = datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900').strftime('%Y-%m-%d')
                
                # ê¸°ê°„ ë‚´ ê¸°ì‚¬ê±°ë‚˜, ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•œ ìµœì†Œ 2ê°œ ìˆ˜ì§‘
                if p_date in allowed_dates or (db_key != "MNO" and tag_count < 2):
                    if post_notion(db_id, title, item['link'], tags, p_date):
                        seen_urls.add(item['link'])
                        seen_titles.append(title)
                        tag_count += 1

if __name__ == "__main__":
    # ê° DBë³„ ìˆ˜ì§‘ ì„¤ì •
    collect("SUBSID", [
        (["SKí…”ë§í¬"], 12, "SKí…”ë§í¬"), (["KTì— ëª¨ë°”ì¼"], 12, "KT Mëª¨ë°”ì¼"),
        (["LGí—¬ë¡œë¹„ì „"], 12, "LGí—¬ë¡œë¹„ì „"), (["ìŠ¤ì¹´ì´ë¼ì´í”„"], 12, "KTìŠ¤ì¹´ì´ë¼ì´í”„"), (["ë¯¸ë””ì–´ë¡œê·¸"], 12, "ë¯¸ë””ì–´ë¡œê·¸")
    ], 60)
    
    collect("MNO", [
        (["í†µì‹ 3ì‚¬", "í†µì‹ ì—…ê³„", "í†µì‹ ì£¼"], 12, "í†µì‹  3ì‚¬"),
        (["SKí…”ë ˆì½¤", "SKT"], 12, "SKT"), (["KT"], 12, "KT"), (["LGìœ í”ŒëŸ¬ìŠ¤"], 12, "LG U+")
    ], 7)
    
    collect("FIN", [(["í† ìŠ¤ëª¨ë°”ì¼", "ë¦¬ë¸Œëª¨ë°”ì¼", "ìš°ë¦¬ì›ëª¨ë°”ì¼"], 12, "ê¸ˆìœµê¶Œ")], 60)
    
    # [ì¤‘ì†Œ ì‚¬ì—…ì] ë‹¨ìˆœíˆ 'ì•Œëœ°í°'ìœ¼ë¡œ ê²€ìƒ‰í•˜ë˜, í•„í„°ì—ì„œ ì§€ì • ì—…ì²´ëª…ë§Œ ê±¸ëŸ¬ëƒ„
    collect("SMALL", [
        (["ì•„ì´ì¦ˆëª¨ë°”ì¼"], 12, "ì•„ì´ì¦ˆëª¨ë°”ì¼"), (["í”„ë¦¬í…”ë ˆì½¤"], 12, "í”„ë¦¬ëª¨ë°”ì¼"),
        (["ì—ë„¥ìŠ¤í…”ë ˆì½¤"], 12, "ì—ë„¥ìŠ¤í…”ë ˆì½¤"), (["ìœ ë‹ˆì»´ì¦ˆ"], 12, "ìœ ë‹ˆì»´ì¦ˆ"),
        (["ì¸ìŠ¤ì½”ë¹„", "í”„ë¦¬í‹°"], 12, "ì¸ìŠ¤ì½”ë¹„"), (["ì„¸ì¢…í…”ë ˆì½¤"], 12, "ì„¸ì¢…í…”ë ˆì½¤"),
        (["í°ì‚¬ëŒ", "ì´ì•¼ê¸°ëª¨ë°”ì¼"], 12, "í°ì‚¬ëŒ")
    ], 60)
