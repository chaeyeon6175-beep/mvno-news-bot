import os, requests, re, time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from difflib import SequenceMatcher

# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
NAVER_ID = os.environ.get('NAVER_CLIENT_ID')
NAVER_SECRET = os.environ.get('NAVER_CLIENT_SECRET')
NOTION_TOKEN = os.environ.get('NOTION_TOKEN')
DB_IDS = {
    "MNO": os.environ.get('DB_ID_MNO'),
    "SUBSID": os.environ.get('DB_ID_SUBSID'),
    "FIN": os.environ.get('DB_ID_FIN'),
    "SMALL": os.environ.get('DB_ID_SMALL')
}

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# ì£¼ìš” ì–¸ë¡ ì‚¬ ê°€ì¤‘ì¹˜ (ëŒ€í‘œ ê¸°ì‚¬ ì„ ì • ì‹œ ì‚¬ìš©)
MAJOR_PRESS = ["ì—°í•©ë‰´ìŠ¤", "ë‰´ì‹œìŠ¤", "ë‰´ìŠ¤1", "ë§¤ì¼ê²½ì œ", "í•œêµ­ê²½ì œ", "ì „ìì‹ ë¬¸", "ë””ì§€í„¸ë°ì¼ë¦¬", "ë¨¸ë‹ˆíˆ¬ë°ì´"]

def clear_notion_database(db_id):
    if not db_id: return
    target_id = re.sub(r'[^a-fA-F0-9]', '', db_id)
    try:
        res = requests.post(f"https://api.notion.com/v1/databases/{target_id}/query", headers=HEADERS)
        if res.status_code == 200:
            for page in res.json().get("results", []):
                requests.patch(f"https://api.notion.com/v1/pages/{page['id']}", headers=HEADERS, json={"archived": True})
    except: pass

def get_similarity(a, b):
    a = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', a)
    b = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', b)
    return SequenceMatcher(None, a, b).ratio()

def select_representative(articles):
    """ìµœì‹ ì„±, ì œëª© êµ¬ì²´ì„±, ì–¸ë¡ ì‚¬ ì‹ ë¢°ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëŒ€í‘œ ê¸°ì‚¬ 1ê°œ ì„ ì •"""
    best_score = -1
    best_art = articles[0]
    for art in articles:
        score = 0
        if any(p in art['press'] for p in MAJOR_PRESS): score += 10
        score += len(art['title']) * 0.1
        if score >= best_score:
            best_score = score
            best_art = art
    return best_art

def get_db_specific_tags(title, db_key, default_tag):
    """DBê°„ ì˜ì—­ ì¹¨ë²” ë°©ì§€ ë° íƒœê·¸ ë¶€ì—¬ ë¡œì§"""
    t = title.lower().replace(' ', '')
    
    # [ê³µí†µ] ì œì™¸ í‚¤ì›Œë“œ í•„í„°
    if any(ex in t for ex in ["skì‰´ë”ìŠ¤", "ì§€ë‹ˆë®¤ì§", "ktì•ŒíŒŒ", "ktalpha"]): return None

    # [ì˜ì—­ ì¹¨ë²” ë°©ì§€ í‚¤ì›Œë“œì…‹]
    mno_kws = ["skí…”ë ˆì½¤", "skt", "kt", "ì¼€ì´í‹°", "lgìœ í”ŒëŸ¬ìŠ¤", "lgu+", "ì—˜ì§€ìœ í”ŒëŸ¬ìŠ¤"]
    subsid_kws = ["í…”ë§í¬", "ì— ëª¨ë°”ì¼", "í—¬ë¡œë¹„ì „", "ìŠ¤ì¹´ì´ë¼ì´í”„", "ë¯¸ë””ì–´ë¡œê·¸"]
    fin_kws = ["ë¦¬ë¸Œëª¨ë°”ì¼", "ë¦¬ë¸Œm", "í† ìŠ¤ëª¨ë°”ì¼", "ìš°ë¦¬ì›ëª¨ë°”ì¼"]

    # 1. MNO DB í•„í„°ë§
    if db_key == "MNO":
        if any(x in t for x in (subsid_kws + fin_kws)): return None
        if not any(x in t for x in mno_kws + ["í†µì‹ ì‚¬", "ì´í†µì‚¬"]): return None
        
        # MNO ë‚´ ì„¸ë¶€ ë¶„ë¥˜ (í†µì‹  3ì‚¬ ìš°ì„ )
        is_3ì‚¬ = any(x in t for x in ["í†µì‹ 3ì‚¬", "ì´í†µ3ì‚¬", "í†µì‹ ì‚¬"]) or \
                 (sum([any(x in t for x in ["skt", "skí…”ë ˆì½¤"]), any(x in t for x in ["kt", "ì¼€ì´í‹°"]), any(x in t for x in ["lgu+", "lgìœ í”ŒëŸ¬ìŠ¤"])]) >= 2)
        if is_3ì‚¬: return [{"name": "í†µì‹  3ì‚¬"}]
        if any(x in t for x in ["skt", "skí…”ë ˆì½¤"]): return [{"name": "SKT"}]
        if any(x in t for x in ["kt", "ì¼€ì´í‹°"]): return [{"name": "KT"}]
        if any(x in t for x in ["lgu+", "lgìœ í”ŒëŸ¬ìŠ¤"]): return [{"name": "LG U+"}]

    # 2. ìíšŒì‚¬ DB í•„í„°ë§
    elif db_key == "SUBSID":
        subsid_map = {
            "SKí…”ë§í¬": ["skí…”ë§í¬", "7ëª¨ë°”ì¼"],
            "KT Mëª¨ë°”ì¼": ["ktmëª¨ë°”ì¼", "ktì— ëª¨ë°”ì¼"],
            "LGí—¬ë¡œë¹„ì „": ["lgí—¬ë¡œë¹„ì „", "í—¬ë¡œëª¨ë°”ì¼"],
            "KTìŠ¤ì¹´ì´ë¼ì´í”„": ["ìŠ¤ì¹´ì´ë¼ì´í”„"],
            "ë¯¸ë””ì–´ë¡œê·¸": ["ë¯¸ë””ì–´ë¡œê·¸", "ìœ ëª¨ë°”ì¼"]
        }
        for name, kws in subsid_map.items():
            if any(x in t for x in kws): return [{"name": name}]
        return None

    # 3. ê¸ˆìœµ DB í•„í„°ë§
    elif db_key == "FIN":
        fin_map = {
            "KBë¦¬ë¸Œëª¨ë°”ì¼": ["ë¦¬ë¸Œëª¨ë°”ì¼", "ë¦¬ë¸Œm"],
            "í† ìŠ¤ëª¨ë°”ì¼": ["í† ìŠ¤ëª¨ë°”ì¼"],
            "ìš°ë¦¬ì›ëª¨ë°”ì¼": ["ìš°ë¦¬ì›ëª¨ë°”ì¼"]
        }
        for name, kws in fin_map.items():
            if any(x in t for x in kws): return [{"name": name}]
        return None

    # 4. ì¤‘ì†ŒíšŒì‚¬ DB í•„í„°ë§ (ë©”ì´ì € í‚¤ì›Œë“œ í¬í•¨ ì‹œ ì œì™¸)
    elif db_key == "SMALL":
        if not "ì•Œëœ°í°" in t: return None
        if any(x in t for x in (mno_kws + subsid_kws + fin_kws)): return None
        return [{"name": "ì¤‘ì†Œ ì•Œëœ°í°"}]

    return None

def post_notion(db_id, title, link, tags, pub_date):
    if not db_id: return False
    target_id = re.sub(r'[^a-fA-F0-9]', '', db_id)
    data = {
        "parent": {"database_id": target_id},
        "properties": {
            "ì œëª©": {"title": [{"text": {"content": title}}]},
            "ë‚ ì§œ": {"rich_text": [{"text": {"content": pub_date}}]},
            "ë§í¬": {"url": link},
            "ë¶„ë¥˜": {"multi_select": tags}
        }
    }
    res = requests.post("https://api.notion.com/v1/pages", headers=HEADERS, json=data)
    return res.status_code == 200

def collect(db_key, configs, days):
    db_id = DB_IDS.get(db_key)
    if not db_id: return
    
    allowed_dates = [(datetime.now() - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days + 1)]
    print(f"ğŸ” {db_key} ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ìˆ˜ì§‘ ì¤‘...")

    for keywords, limit, default_tag in configs:
        query = " ".join(keywords)
        raw_items = []
        for sort_type in ["date", "sim"]:
            url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100&sort={sort_type}"
            res = requests.get(url, headers={"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET})
            if res.status_code == 200: raw_items.extend(res.json().get('items', []))
        
        # 1. ìœ íš¨ì„± ê²€ì‚¬ ë° ì •í˜•í™”
        valid_articles = []
        for item in raw_items:
            title = item['title'].replace('<b>','').replace('</b>','').replace('&quot;','"')
            tags = get_db_specific_tags(title, db_key, default_tag)
            if tags:
                valid_articles.append({
                    'title': title, 'link': item['link'], 'tags': tags,
                    'date': datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900').strftime('%Y-%m-%d'),
                    'press': item.get('originallink', '')
                })

        # 2. ìœ ì‚¬ ê¸°ì‚¬ ê·¸ë£¹í™” (Clustering)
        unique_groups = []
        for art in valid_articles:
            found = False
            for group in unique_groups:
                if get_similarity(art['title'], group[0]['title']) > 0.6:
                    group.append(art); found = True; break
            if not found: unique_groups.append([art])

        # 3. ëŒ€í‘œ ê¸°ì‚¬ ì„ ì • ë° ë“±ë¡
        count = 0
        for group in unique_groups:
            rep = select_representative(group)
            is_min = (db_key != "MNO") and (count < 2) # ìµœì†Œ 2ê°œ ë³´ì¥
            if rep['date'] in allowed_dates or is_min:
                if post_notion(db_id, rep['title'], rep['link'], rep['tags'], rep['date']):
                    count += 1
            if count >= min(limit, 12): break

if __name__ == "__main__":
    for k in DB_IDS: clear_notion_database(DB_IDS[k])
    
    # 1. ìíšŒì‚¬ (5ê°œì‚¬)
    collect("SUBSID", [(["SKí…”ë§í¬", "KTì— ëª¨ë°”ì¼", "LGí—¬ë¡œë¹„ì „", "ìŠ¤ì¹´ì´ë¼ì´í”„", "ë¯¸ë””ì–´ë¡œê·¸"], 12, "ìíšŒì‚¬")], 60)
    # 2. MNO (ìˆœìˆ˜ 3ì‚¬)
    collect("MNO", [(["í†µì‹ 3ì‚¬"], 12, "í†µì‹  3ì‚¬"), (["SKT"], 12, "SKT"), (["KT"], 12, "KT"), (["LGìœ í”ŒëŸ¬ìŠ¤"], 12, "LG U+")], 7)
    # 3. ê¸ˆìœµ
    collect("FIN", [(["í† ìŠ¤ëª¨ë°”ì¼", "ë¦¬ë¸Œëª¨ë°”ì¼", "ìš°ë¦¬ì›ëª¨ë°”ì¼"], 12, "ê¸ˆìœµê¶Œ")], 60)
    # 4. ì¤‘ì†Œ
    collect("SMALL", [(["ì•Œëœ°í°"], 12, "ì¤‘ì†Œ ì•Œëœ°í°")], 60)

    print("ğŸ ëª¨ë“  í•„í„°ë§, ê·¸ë£¹í™”, ëŒ€í‘œ ê¸°ì‚¬ ì„ ì • í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
